{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# node2vec\n",
    "---\n",
    "[node2vec](http://snap.stanford.edu/node2vec/) for link prediction:\n",
    "1. Perform train-test split\n",
    "1. Train skip-gram model on random walks within training graph\n",
    "2. Get node embeddings from skip-gram model\n",
    "3. Create bootstrapped edge embeddings by taking the Hadamard product of node embeddings\n",
    "4. Train a logistic regression classifier on these edge embeddings (possible edge --> edge score between 0-1)\n",
    "5. Evaluate these edge embeddings on the validation and test edge sets\n",
    "\n",
    "node2vec source code: https://github.com/aditya-grover/node2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read in Graph Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "import pickle\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import dok_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#EGO_USER = 0 # which ego network to look at\n",
    "\n",
    "# Load pickled (adj, feat) tuple\n",
    "#network_dir = './fb-processed/{0}-adj-feat.pkl'.format(EGO_USER)\n",
    "#with open(network_dir, 'rb') as f:\n",
    "#    adj, features = pickle.load(f)\n",
    "    \n",
    "#g = nx.Graph(adj) # re-create graph using node indices (0 to num_nodes-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<40770x40770 sparse matrix of type '<type 'numpy.int32'>'\n",
       "\twith 60412 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"./patent/train1988-1990.txt\"\n",
    "\n",
    "fin = open(file_path, \"r\")\n",
    "firstLine = fin.readline().strip().split()\n",
    "N = int(firstLine[0])\n",
    "E = int(firstLine[1])\n",
    "adj_matrix = dok_matrix((N, N), dtype=np.int32)\n",
    "count = 0\n",
    "for line in fin.readlines():\n",
    "    line = line.strip().split()\n",
    "    x = int(line[0])\n",
    "    y = int(line[1])\n",
    "    adj_matrix[x, y] = 1\n",
    "    adj_matrix[y, x] = 1\n",
    "    count += 1\n",
    "fin.close()\n",
    "adj_matrix = adj_matrix.tocsr()\n",
    "adj_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = nx.Graph(adj_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# draw network\n",
    "#nx.draw_networkx(g, with_labels=False, node_size=50, node_color='r')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing/Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing...\n",
      "generating test/val sets...\n",
      "creating false test edges...\n",
      "creating false val edges...\n",
      "creating false train edges...\n",
      "final checks for disjointness...\n",
      "creating adj_train...\n",
      "Done with train-test split!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from gae.preprocessing import mask_test_edges\n",
    "np.random.seed(0) # make sure train-test split is consistent between notebooks\n",
    "adj_sparse = nx.to_scipy_sparse_matrix(g)\n",
    "\n",
    "# Perform train-test split\n",
    "adj_train, train_edges, train_edges_false, val_edges, val_edges_false, \\\n",
    "    test_edges, test_edges_false = mask_test_edges(adj_sparse, test_frac=.10, val_frac=.05, prevent_disconnect=False, verbose=True)\n",
    "g_train = nx.from_scipy_sparse_matrix(adj_train) # new graph object with only non-hidden edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total nodes: 40770\n",
      "Total edges: 30206\n",
      "Training edges (positive): 25676\n",
      "Training edges (negative): 25676\n",
      "Validation edges (positive): 1510\n",
      "Validation edges (negative): 1510\n",
      "Test edges (positive): 3020\n",
      "Test edges (negative): 3020\n"
     ]
    }
   ],
   "source": [
    "# Inspect train/test split\n",
    "print \"Total nodes:\", adj_sparse.shape[0]\n",
    "print \"Total edges:\", int(adj_sparse.nnz/2) # adj is symmetric, so nnz (num non-zero) = 2*num_edges\n",
    "print \"Training edges (positive):\", len(train_edges)\n",
    "print \"Training edges (negative):\", len(train_edges_false)\n",
    "print \"Validation edges (positive):\", len(val_edges)\n",
    "print \"Validation edges (negative):\", len(val_edges_false)\n",
    "print \"Test edges (positive):\", len(test_edges)\n",
    "print \"Test edges (negative):\", len(test_edges_false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train node2vec (Learn Node Embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handlers could be found for logger \"smart_open.ssh\"\n"
     ]
    }
   ],
   "source": [
    "import node2vec\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# node2vec settings\n",
    "# NOTE: When p = q = 1, this is equivalent to DeepWalk\n",
    "\n",
    "P = 1 # Return hyperparameter\n",
    "Q = 1 # In-out hyperparameter\n",
    "WINDOW_SIZE = 10 # Context size for optimization\n",
    "NUM_WALKS = 10 # Number of walks per source\n",
    "WALK_LENGTH = 40 # Length of walk per source\n",
    "DIMENSIONS = 64 # Embedding dimension\n",
    "DIRECTED = False # Graph directed/undirected\n",
    "WORKERS = 8 # Num. parallel workers\n",
    "ITER = 1 # SGD epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walk iteration:\n",
      "1 / 10\n",
      "2 / 10\n",
      "3 / 10\n",
      "4 / 10\n",
      "5 / 10\n",
      "6 / 10\n",
      "7 / 10\n",
      "8 / 10\n",
      "9 / 10\n",
      "10 / 10\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing, generate walks\n",
    "g_n2v = node2vec.Graph(g_train, DIRECTED, P, Q) # create node2vec graph instance\n",
    "g_n2v.preprocess_transition_probs()\n",
    "walks = g_n2v.simulate_walks(NUM_WALKS, WALK_LENGTH)\n",
    "walks = [map(str, walk) for walk in walks]\n",
    "\n",
    "# Train skip-gram model\n",
    "model = Word2Vec(walks, size=DIMENSIONS, window=WINDOW_SIZE, min_count=0, sg=1, workers=WORKERS, iter=ITER)\n",
    "\n",
    "# Store embeddings mapping\n",
    "emb_mappings = model.wv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Edge Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create node embeddings matrix (rows = nodes, columns = embedding features)\n",
    "emb_list = []\n",
    "for node_index in range(0, adj_sparse.shape[0]):\n",
    "    node_str = str(node_index)\n",
    "    node_emb = emb_mappings[node_str]\n",
    "    emb_list.append(node_emb)\n",
    "emb_matrix = np.vstack(emb_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate bootstrapped edge embeddings (as is done in node2vec paper)\n",
    "    # Edge embedding for (v1, v2) = hadamard product of node embeddings for v1, v2\n",
    "def get_edge_embeddings(edge_list):\n",
    "    embs = []\n",
    "    for edge in edge_list:\n",
    "        node1 = edge[0]\n",
    "        node2 = edge[1]\n",
    "        emb1 = emb_matrix[node1]\n",
    "        emb2 = emb_matrix[node2]\n",
    "        edge_emb = np.multiply(emb1, emb2)\n",
    "        embs.append(edge_emb)\n",
    "    embs = np.array(embs)\n",
    "    return embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train-set edge embeddings\n",
    "pos_train_edge_embs = get_edge_embeddings(train_edges)\n",
    "neg_train_edge_embs = get_edge_embeddings(train_edges_false)\n",
    "train_edge_embs = np.concatenate([pos_train_edge_embs, neg_train_edge_embs])\n",
    "\n",
    "# Create train-set edge labels: 1 = real edge, 0 = false edge\n",
    "train_edge_labels = np.concatenate([np.ones(len(train_edges)), np.zeros(len(train_edges_false))])\n",
    "\n",
    "# Val-set edge embeddings, labels\n",
    "pos_val_edge_embs = get_edge_embeddings(val_edges)\n",
    "neg_val_edge_embs = get_edge_embeddings(val_edges_false)\n",
    "val_edge_embs = np.concatenate([pos_val_edge_embs, neg_val_edge_embs])\n",
    "val_edge_labels = np.concatenate([np.ones(len(val_edges)), np.zeros(len(val_edges_false))])\n",
    "\n",
    "# Test-set edge embeddings, labels\n",
    "pos_test_edge_embs = get_edge_embeddings(test_edges)\n",
    "neg_test_edge_embs = get_edge_embeddings(test_edges_false)\n",
    "test_edge_embs = np.concatenate([pos_test_edge_embs, neg_test_edge_embs])\n",
    "\n",
    "# Create val-set edge labels: 1 = real edge, 0 = false edge\n",
    "test_edge_labels = np.concatenate([np.ones(len(test_edges)), np.zeros(len(test_edges_false))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate Edge Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=0, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train logistic regression classifier on train-set edge embeddings\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score\n",
    "edge_classifier = LogisticRegression(random_state=0)\n",
    "edge_classifier.fit(train_edge_embs, train_edge_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predicted edge scores: probability of being of class \"1\" (real edge)\n",
    "val_preds = edge_classifier.predict_proba(val_edge_embs)[:, 1]\n",
    "val_roc = roc_auc_score(val_edge_labels, val_preds)\n",
    "val_ap = average_precision_score(val_edge_labels, val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predicted edge scores: probability of being of class \"1\" (real edge)\n",
    "test_preds = edge_classifier.predict_proba(test_edge_embs)[:, 1]\n",
    "test_roc = roc_auc_score(test_edge_labels, test_preds)\n",
    "test_ap = average_precision_score(test_edge_labels, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node2vec Validation ROC score:  0.28732731020569274\n",
      "node2vec Validation AP score:  0.4725406124401903\n",
      "node2vec Test ROC score:  0.2738612341563966\n",
      "node2vec Test AP score:  0.459595236041642\n"
     ]
    }
   ],
   "source": [
    "print 'node2vec Validation ROC score: ', str(val_roc)\n",
    "print 'node2vec Validation AP score: ', str(val_ap)\n",
    "print 'node2vec Test ROC score: ', str(test_roc)\n",
    "print 'node2vec Test AP score: ', str(test_ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision@10 = 0.100000\n",
      "precision@50 = 0.100000\n",
      "precision@100 = 0.080000\n",
      "precision@500 = 0.104000\n",
      "precision@1000 = 0.100000\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "K = [10,50,100,500,1000]\n",
    "\n",
    "N = int(len(test_edge_labels)/2)\n",
    "#print(N)\n",
    "\n",
    "test_class_preds = edge_classifier.predict(test_edge_embs[:,:])\n",
    "\n",
    "for i in range(0,len(K)):\n",
    "    setK = np.sort(np.random.choice(N, K[i]))\n",
    "\n",
    "    set_class_preds = test_class_preds[setK]\n",
    "    nt = np.count_nonzero(set_class_preds)\n",
    "    score = nt / K[i]\n",
    "    print(\"precision@%d = %f\" % (K[i],score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
