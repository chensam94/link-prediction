{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# node2vec\n",
    "---\n",
    "[node2vec](http://snap.stanford.edu/node2vec/) for link prediction:\n",
    "1. Perform train-test split\n",
    "1. Train skip-gram model on random walks within training graph\n",
    "2. Get node embeddings from skip-gram model\n",
    "3. Create bootstrapped edge embeddings by taking the Hadamard product of node embeddings\n",
    "4. Train a logistic regression classifier on these edge embeddings (possible edge --> edge score between 0-1)\n",
    "5. Evaluate these edge embeddings on the validation and test edge sets\n",
    "\n",
    "node2vec source code: https://github.com/aditya-grover/node2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read in Graph Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "import pickle\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import dok_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EGO_USER = 0 # which ego network to look at\n",
    "\n",
    "# Load pickled (adj, feat) tuple\n",
    "network_dir = './fb-processed/{0}-adj-feat.pkl'.format(EGO_USER)\n",
    "with open(network_dir, 'rb') as f:\n",
    "    adj, features = pickle.load(f)\n",
    "    \n",
    "g = nx.Graph(adj) # re-create graph using node indices (0 to num_nodes-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"./patent/omitted1990-1997.txt\"\n",
    "\n",
    "fin = open(file_path, \"r\")\n",
    "firstLine = fin.readline().strip().split()\n",
    "N = int(firstLine[0])\n",
    "E = int(firstLine[1])\n",
    "adj_matrix = dok_matrix((N, N), np.int_)\n",
    "count = 0\n",
    "for line in fin.readlines():\n",
    "    line = line.strip().split()\n",
    "    x = int(line[0])\n",
    "    y = int(line[1])\n",
    "    adj_matrix[x, y] += 1\n",
    "    adj_matrix[y, x] += 1\n",
    "    count += 1\n",
    "fin.close()\n",
    "adj_matrix = adj_matrix.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_matrix\n",
    "g = nx.Graph(adj_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw network\n",
    "nx.draw_networkx(g, with_labels=False, node_size=50, node_color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing/Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gae.preprocessing import mask_test_edges\n",
    "np.random.seed(0) # make sure train-test split is consistent between notebooks\n",
    "adj_sparse = nx.to_scipy_sparse_matrix(g)\n",
    "\n",
    "# Perform train-test split\n",
    "adj_train, train_edges, train_edges_false, val_edges, val_edges_false, \\\n",
    "    test_edges, test_edges_false = mask_test_edges(adj_sparse, test_frac=.3, val_frac=.1)\n",
    "g_train = nx.from_scipy_sparse_matrix(adj_train) # new graph object with only non-hidden edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect train/test split\n",
    "print \"Total nodes:\", adj_sparse.shape[0]\n",
    "print \"Total edges:\", int(adj_sparse.nnz/2) # adj is symmetric, so nnz (num non-zero) = 2*num_edges\n",
    "print \"Training edges (positive):\", len(train_edges)\n",
    "print \"Training edges (negative):\", len(train_edges_false)\n",
    "print \"Validation edges (positive):\", len(val_edges)\n",
    "print \"Validation edges (negative):\", len(val_edges_false)\n",
    "print \"Test edges (positive):\", len(test_edges)\n",
    "print \"Test edges (negative):\", len(test_edges_false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train node2vec (Learn Node Embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import node2vec\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# node2vec settings\n",
    "# NOTE: When p = q = 1, this is equivalent to DeepWalk\n",
    "\n",
    "P = 1 # Return hyperparameter\n",
    "Q = 1 # In-out hyperparameter\n",
    "WINDOW_SIZE = 10 # Context size for optimization\n",
    "NUM_WALKS = 10 # Number of walks per source\n",
    "WALK_LENGTH = 80 # Length of walk per source\n",
    "DIMENSIONS = 128 # Embedding dimension\n",
    "DIRECTED = False # Graph directed/undirected\n",
    "WORKERS = 8 # Num. parallel workers\n",
    "ITER = 1 # SGD epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing, generate walks\n",
    "g_n2v = node2vec.Graph(g_train, DIRECTED, P, Q) # create node2vec graph instance\n",
    "g_n2v.preprocess_transition_probs()\n",
    "walks = g_n2v.simulate_walks(NUM_WALKS, WALK_LENGTH)\n",
    "walks = [map(str, walk) for walk in walks]\n",
    "\n",
    "# Train skip-gram model\n",
    "model = Word2Vec(walks, size=DIMENSIONS, window=WINDOW_SIZE, min_count=0, sg=1, workers=WORKERS, iter=ITER)\n",
    "\n",
    "# Store embeddings mapping\n",
    "emb_mappings = model.wv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Edge Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create node embeddings matrix (rows = nodes, columns = embedding features)\n",
    "emb_list = []\n",
    "for node_index in range(0, adj_sparse.shape[0]):\n",
    "    node_str = str(node_index)\n",
    "    node_emb = emb_mappings[node_str]\n",
    "    emb_list.append(node_emb)\n",
    "emb_matrix = np.vstack(emb_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate bootstrapped edge embeddings (as is done in node2vec paper)\n",
    "    # Edge embedding for (v1, v2) = hadamard product of node embeddings for v1, v2\n",
    "def get_edge_embeddings(edge_list):\n",
    "    embs = []\n",
    "    for edge in edge_list:\n",
    "        node1 = edge[0]\n",
    "        node2 = edge[1]\n",
    "        emb1 = emb_matrix[node1]\n",
    "        emb2 = emb_matrix[node2]\n",
    "        edge_emb = np.multiply(emb1, emb2)\n",
    "        embs.append(edge_emb)\n",
    "    embs = np.array(embs)\n",
    "    return embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-set edge embeddings\n",
    "pos_train_edge_embs = get_edge_embeddings(train_edges)\n",
    "neg_train_edge_embs = get_edge_embeddings(train_edges_false)\n",
    "train_edge_embs = np.concatenate([pos_train_edge_embs, neg_train_edge_embs])\n",
    "\n",
    "# Create train-set edge labels: 1 = real edge, 0 = false edge\n",
    "train_edge_labels = np.concatenate([np.ones(len(train_edges)), np.zeros(len(train_edges_false))])\n",
    "\n",
    "# Val-set edge embeddings, labels\n",
    "pos_val_edge_embs = get_edge_embeddings(val_edges)\n",
    "neg_val_edge_embs = get_edge_embeddings(val_edges_false)\n",
    "val_edge_embs = np.concatenate([pos_val_edge_embs, neg_val_edge_embs])\n",
    "val_edge_labels = np.concatenate([np.ones(len(val_edges)), np.zeros(len(val_edges_false))])\n",
    "\n",
    "# Test-set edge embeddings, labels\n",
    "pos_test_edge_embs = get_edge_embeddings(test_edges)\n",
    "neg_test_edge_embs = get_edge_embeddings(test_edges_false)\n",
    "test_edge_embs = np.concatenate([pos_test_edge_embs, neg_test_edge_embs])\n",
    "\n",
    "# Create val-set edge labels: 1 = real edge, 0 = false edge\n",
    "test_edge_labels = np.concatenate([np.ones(len(test_edges)), np.zeros(len(test_edges_false))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate Edge Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train logistic regression classifier on train-set edge embeddings\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "edge_classifier = LogisticRegression(random_state=0)\n",
    "edge_classifier.fit(train_edge_embs, train_edge_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted edge scores: probability of being of class \"1\" (real edge)\n",
    "val_preds = edge_classifier.predict_proba(val_edge_embs)[:, 1]\n",
    "val_roc = roc_auc_score(val_edge_labels, val_preds)\n",
    "val_ap = average_precision_score(val_edge_labels, val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted edge scores: probability of being of class \"1\" (real edge)\n",
    "test_preds = edge_classifier.predict_proba(test_edge_embs)[:, 1]\n",
    "test_roc = roc_auc_score(test_edge_labels, test_preds)\n",
    "test_ap = average_precision_score(test_edge_labels, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'node2vec Validation ROC score: ', str(val_roc)\n",
    "print 'node2vec Validation AP score: ', str(val_ap)\n",
    "print 'node2vec Test ROC score: ', str(test_roc)\n",
    "print 'node2vec Test AP score: ', str(test_ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
